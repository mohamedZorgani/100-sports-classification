{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5595172,"sourceType":"datasetVersion","datasetId":1209061}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torchvision.models import resnet18","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.068093Z","iopub.execute_input":"2025-01-21T20:19:41.068413Z","iopub.status.idle":"2025-01-21T20:19:41.072786Z","shell.execute_reply.started":"2025-01-21T20:19:41.068386Z","shell.execute_reply":"2025-01-21T20:19:41.071777Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.Resize(232),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.078787Z","iopub.execute_input":"2025-01-21T20:19:41.078997Z","iopub.status.idle":"2025-01-21T20:19:41.094443Z","shell.execute_reply.started":"2025-01-21T20:19:41.078979Z","shell.execute_reply":"2025-01-21T20:19:41.093700Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"train_dataset = torchvision.datasets.ImageFolder(root=\"/kaggle/input/sports-classification/train\", transform=transform_train)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.095566Z","iopub.execute_input":"2025-01-21T20:19:41.095797Z","iopub.status.idle":"2025-01-21T20:19:41.278423Z","shell.execute_reply.started":"2025-01-21T20:19:41.095777Z","shell.execute_reply":"2025-01-21T20:19:41.277690Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"test_dataset = torchvision.datasets.ImageFolder(root=\"/kaggle/input/sports-classification/test\", transform=transform_test)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.279935Z","iopub.execute_input":"2025-01-21T20:19:41.280254Z","iopub.status.idle":"2025-01-21T20:19:41.395137Z","shell.execute_reply.started":"2025-01-21T20:19:41.280220Z","shell.execute_reply":"2025-01-21T20:19:41.394467Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"val_dataset = torchvision.datasets.ImageFolder(root=\"/kaggle/input/sports-classification/valid\", transform=transform_test)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.396288Z","iopub.execute_input":"2025-01-21T20:19:41.396504Z","iopub.status.idle":"2025-01-21T20:19:41.467940Z","shell.execute_reply.started":"2025-01-21T20:19:41.396485Z","shell.execute_reply":"2025-01-21T20:19:41.466982Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"print(\"train size:\",len(train_dataset))\nprint(\"val size:\",len(val_dataset))\nprint(\"test size:\",len(test_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.468931Z","iopub.execute_input":"2025-01-21T20:19:41.469257Z","iopub.status.idle":"2025-01-21T20:19:41.474645Z","shell.execute_reply.started":"2025-01-21T20:19:41.469226Z","shell.execute_reply":"2025-01-21T20:19:41.473713Z"}},"outputs":[{"name":"stdout","text":"train size: 13492\nval size: 500\ntest size: 500\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"weight = torchvision.models.ResNet50_Weights.DEFAULT\nmodel = resnet50(weights = weight)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.475385Z","iopub.execute_input":"2025-01-21T20:19:41.475584Z","iopub.status.idle":"2025-01-21T20:19:41.946381Z","shell.execute_reply.started":"2025-01-21T20:19:41.475559Z","shell.execute_reply":"2025-01-21T20:19:41.945433Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"model.fc.out_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.948582Z","iopub.execute_input":"2025-01-21T20:19:41.948813Z","iopub.status.idle":"2025-01-21T20:19:41.953944Z","shell.execute_reply.started":"2025-01-21T20:19:41.948793Z","shell.execute_reply":"2025-01-21T20:19:41.953106Z"}},"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":95},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.955241Z","iopub.execute_input":"2025-01-21T20:19:41.955531Z","iopub.status.idle":"2025-01-21T20:19:41.967459Z","shell.execute_reply.started":"2025-01-21T20:19:41.955501Z","shell.execute_reply":"2025-01-21T20:19:41.966687Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"custom_fc = nn.Sequential(\n    nn.ReLU(),\n    nn.Dropout(p = 0.5),\n    nn.Linear(1000, 100))\n\nmodel.fc = nn.Sequential(\n    model.fc,\n    custom_fc\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.968281Z","iopub.execute_input":"2025-01-21T20:19:41.968563Z","iopub.status.idle":"2025-01-21T20:19:41.985004Z","shell.execute_reply.started":"2025-01-21T20:19:41.968532Z","shell.execute_reply":"2025-01-21T20:19:41.984367Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"# Training settings\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(torch.cuda.is_available())\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0005)\n#scheduler = lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:41.985916Z","iopub.execute_input":"2025-01-21T20:19:41.986224Z","iopub.status.idle":"2025-01-21T20:19:42.036349Z","shell.execute_reply.started":"2025-01-21T20:19:41.986194Z","shell.execute_reply":"2025-01-21T20:19:42.035535Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"# Training Loop with Validation Loss and Accuracy\nnum_epochs = 100\n\nfor epoch in range(num_epochs):\n    # Training Phase\n    model.train()  # Set the model to training mode\n    running_train_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()  # Zero the gradients\n        outputs = model(images)  # Forward pass\n        loss = criterion(outputs, labels)  # Compute loss\n        loss.backward()  # Backpropagation\n        optimizer.step()  # Update model parameters\n        \n        running_train_loss += loss.item()  # Accumulate training loss\n        \n        # Track training accuracy\n        _, predicted = outputs.max(1)\n        total_train += labels.size(0)\n        correct_train += predicted.eq(labels).sum().item()\n    \n    train_loss = running_train_loss / len(train_loader)\n    train_accuracy = 100 * correct_train / total_train\n\n    # Validation Phase\n    model.eval()  # Set the model to evaluation mode\n    running_val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    \n    with torch.no_grad():  \n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute validation loss\n            running_val_loss += loss.item()\n            \n            # Track validation accuracy\n            _, predicted = outputs.max(1)\n            total_val += labels.size(0)\n            correct_val += predicted.eq(labels).sum().item()\n    \n    val_loss = running_val_loss / len(test_loader)\n    val_accuracy = 100 * correct_val / total_val\n\n    # Print training and validation metrics\n    print(f'Epoch [{epoch + 1}/{num_epochs}]')\n    print(f'Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%')\n    print(f'Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.2f}%')\n    \n    scheduler.step()  # Adjust learning rate according to the scheduler\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:19:42.037271Z","iopub.execute_input":"2025-01-21T20:19:42.037490Z","iopub.status.idle":"2025-01-21T20:39:00.900478Z","shell.execute_reply.started":"2025-01-21T20:19:42.037460Z","shell.execute_reply":"2025-01-21T20:39:00.899264Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/100]\nTrain Loss: 1.6002 | Train Accuracy: 58.81%\nVal Loss: 0.7476 | Val Accuracy: 80.80%\nEpoch [2/100]\nTrain Loss: 0.5905 | Train Accuracy: 82.69%\nVal Loss: 0.6195 | Val Accuracy: 83.00%\nEpoch [3/100]\nTrain Loss: 0.3836 | Train Accuracy: 88.84%\nVal Loss: 0.5436 | Val Accuracy: 87.00%\nEpoch [4/100]\nTrain Loss: 0.2828 | Train Accuracy: 91.64%\nVal Loss: 0.2887 | Val Accuracy: 90.60%\nEpoch [5/100]\nTrain Loss: 0.2306 | Train Accuracy: 93.10%\nVal Loss: 0.3580 | Val Accuracy: 91.00%\nEpoch [6/100]\nTrain Loss: 0.2114 | Train Accuracy: 93.66%\nVal Loss: 0.6907 | Val Accuracy: 85.40%\nEpoch [7/100]\nTrain Loss: 0.1927 | Train Accuracy: 94.36%\nVal Loss: 0.3089 | Val Accuracy: 90.20%\nEpoch [8/100]\nTrain Loss: 0.1567 | Train Accuracy: 94.89%\nVal Loss: 0.3612 | Val Accuracy: 91.20%\nEpoch [9/100]\nTrain Loss: 0.1315 | Train Accuracy: 96.01%\nVal Loss: 0.3628 | Val Accuracy: 90.80%\nEpoch [10/100]\nTrain Loss: 0.1176 | Train Accuracy: 96.52%\nVal Loss: 0.4274 | Val Accuracy: 89.00%\nEpoch [11/100]\nTrain Loss: 0.1446 | Train Accuracy: 95.58%\nVal Loss: 0.2772 | Val Accuracy: 92.00%\nEpoch [12/100]\nTrain Loss: 0.1206 | Train Accuracy: 96.54%\nVal Loss: 0.4566 | Val Accuracy: 87.20%\nEpoch [13/100]\nTrain Loss: 0.0964 | Train Accuracy: 96.92%\nVal Loss: 0.4544 | Val Accuracy: 91.20%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-99-6e6434cb3260>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mrunning_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Accumulate training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Track training accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":99},{"cell_type":"code","source":"def check_accuracy(loader,model):\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n\n    with torch.no_grad():\n        for x,y in loader:\n            x = x.to(device = device)\n            y = y.to(device = device)\n\n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n    #model.train()\n    return num_correct / num_samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:39:05.336707Z","iopub.execute_input":"2025-01-21T20:39:05.337125Z","iopub.status.idle":"2025-01-21T20:39:05.342280Z","shell.execute_reply.started":"2025-01-21T20:39:05.337087Z","shell.execute_reply":"2025-01-21T20:39:05.341274Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"check_accuracy(test_loader,model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:39:28.266218Z","iopub.execute_input":"2025-01-21T20:39:28.266533Z","iopub.status.idle":"2025-01-21T20:39:29.672614Z","shell.execute_reply.started":"2025-01-21T20:39:28.266507Z","shell.execute_reply":"2025-01-21T20:39:29.671635Z"}},"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"tensor(0.9200, device='cuda:0')"},"metadata":{}}],"execution_count":101},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\n\ndef evaluate_model(model, dataloader, device):\n    model.eval()\n    \n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            # Forward pass to get predictions\n            outputs = model(inputs)\n            \n            # Get the predicted class by taking the max output probability\n            _, predicted = torch.max(outputs, 1)\n            \n            # Store predictions and true labels\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(targets.cpu().numpy())\n    \n    # Convert lists to NumPy arrays for sklearn functions\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    \n    # Classification Report\n    print(\"Classification Report:\")\n    print(classification_report(all_labels, all_preds))\n    \n    # Confusion Matrix\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(all_labels, all_preds))\n    \n    return all_preds, all_labels\n\n\npredictions, true_labels = evaluate_model(model, test_loader, device='cuda')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:47:51.083745Z","iopub.execute_input":"2025-01-21T20:47:51.084293Z","iopub.status.idle":"2025-01-21T20:47:52.322056Z","shell.execute_reply.started":"2025-01-21T20:47:51.084257Z","shell.execute_reply":"2025-01-21T20:47:52.320852Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         5\n           1       1.00      1.00      1.00         5\n           2       1.00      1.00      1.00         5\n           3       1.00      1.00      1.00         5\n           4       1.00      0.80      0.89         5\n           5       1.00      1.00      1.00         5\n           6       1.00      1.00      1.00         5\n           7       1.00      0.60      0.75         5\n           8       1.00      1.00      1.00         5\n           9       1.00      0.60      0.75         5\n          10       1.00      1.00      1.00         5\n          11       1.00      1.00      1.00         5\n          12       1.00      0.60      0.75         5\n          13       0.80      0.80      0.80         5\n          14       1.00      1.00      1.00         5\n          15       0.83      1.00      0.91         5\n          16       0.62      1.00      0.77         5\n          17       0.83      1.00      0.91         5\n          18       1.00      1.00      1.00         5\n          19       0.83      1.00      0.91         5\n          20       1.00      1.00      1.00         5\n          21       1.00      1.00      1.00         5\n          22       1.00      0.80      0.89         5\n          23       1.00      1.00      1.00         5\n          24       1.00      1.00      1.00         5\n          25       0.83      1.00      0.91         5\n          26       0.71      1.00      0.83         5\n          27       1.00      1.00      1.00         5\n          28       1.00      1.00      1.00         5\n          29       1.00      1.00      1.00         5\n          30       1.00      1.00      1.00         5\n          31       1.00      1.00      1.00         5\n          32       0.83      1.00      0.91         5\n          33       0.80      0.80      0.80         5\n          34       0.80      0.80      0.80         5\n          35       0.83      1.00      0.91         5\n          36       1.00      1.00      1.00         5\n          37       1.00      1.00      1.00         5\n          38       1.00      1.00      1.00         5\n          39       1.00      1.00      1.00         5\n          40       0.56      1.00      0.71         5\n          41       0.83      1.00      0.91         5\n          42       1.00      0.60      0.75         5\n          43       0.62      1.00      0.77         5\n          44       1.00      1.00      1.00         5\n          45       1.00      1.00      1.00         5\n          46       1.00      0.60      0.75         5\n          47       1.00      1.00      1.00         5\n          48       1.00      1.00      1.00         5\n          49       1.00      1.00      1.00         5\n          50       0.56      1.00      0.71         5\n          51       1.00      0.40      0.57         5\n          52       1.00      1.00      1.00         5\n          53       1.00      1.00      1.00         5\n          54       1.00      0.80      0.89         5\n          55       0.71      1.00      0.83         5\n          56       0.71      1.00      0.83         5\n          57       1.00      1.00      1.00         5\n          58       1.00      1.00      1.00         5\n          59       0.83      1.00      0.91         5\n          60       1.00      1.00      1.00         5\n          61       1.00      0.80      0.89         5\n          62       1.00      1.00      1.00         5\n          63       1.00      0.40      0.57         5\n          64       1.00      1.00      1.00         5\n          65       1.00      1.00      1.00         5\n          66       1.00      1.00      1.00         5\n          67       0.83      1.00      0.91         5\n          68       1.00      0.60      0.75         5\n          69       0.83      1.00      0.91         5\n          70       1.00      1.00      1.00         5\n          71       1.00      1.00      1.00         5\n          72       0.83      1.00      0.91         5\n          73       1.00      0.80      0.89         5\n          74       1.00      1.00      1.00         5\n          75       0.80      0.80      0.80         5\n          76       1.00      1.00      1.00         5\n          77       0.83      1.00      0.91         5\n          78       1.00      0.80      0.89         5\n          79       1.00      0.60      0.75         5\n          80       1.00      0.80      0.89         5\n          81       1.00      1.00      1.00         5\n          82       1.00      0.20      0.33         5\n          83       0.83      1.00      0.91         5\n          84       1.00      1.00      1.00         5\n          85       1.00      0.80      0.89         5\n          86       1.00      1.00      1.00         5\n          87       1.00      1.00      1.00         5\n          88       1.00      1.00      1.00         5\n          89       1.00      1.00      1.00         5\n          90       1.00      1.00      1.00         5\n          91       1.00      0.60      0.75         5\n          92       0.71      1.00      0.83         5\n          93       1.00      1.00      1.00         5\n          94       1.00      1.00      1.00         5\n          95       0.83      1.00      0.91         5\n          96       1.00      1.00      1.00         5\n          97       1.00      1.00      1.00         5\n          98       1.00      1.00      1.00         5\n          99       1.00      0.60      0.75         5\n\n    accuracy                           0.92       500\n   macro avg       0.94      0.92      0.92       500\nweighted avg       0.94      0.92      0.92       500\n\nConfusion Matrix:\n[[5 0 0 ... 0 0 0]\n [0 5 0 ... 0 0 0]\n [0 0 5 ... 0 0 0]\n ...\n [0 0 0 ... 5 0 0]\n [0 0 0 ... 0 5 0]\n [0 0 0 ... 0 0 3]]\n","output_type":"stream"}],"execution_count":104}]}